# -*- coding: utf-8 -*-
"""LifeExpectancy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VWfWrgylcmL9Ivkbw2yYO_eRgiq2ICQG
"""

import pandas as pd
import numpy as np

df = pd.read_csv('/content/Life Expectancy Data.csv')

df.head()

df.info()

df.describe()

df.hist(bins = 30, figsize = [20,20])

df.columns
countries = list(df['Country'].unique())

!pip install pycountry_convert

import pycountry_convert as pc

def country_to_continent(country_name):
    try:
        country_code = pc.country_name_to_country_alpha2(country_name)
        continent_code = pc.country_alpha2_to_continent_code(country_code)
        continent_name = pc.convert_continent_code_to_continent_name(continent_code)
        return continent_name
    except:
        return None

continents1 = [
    "Africa",
    "Antarctica",
    "Asia",
    "Europe",
    "North America",
    "Oceania",   # (sometimes called Australia in older usage)
    "South America"
]

df['Country'] = df['Country'].map(lambda x: 'Bolivia' if x == 'Bolivia (Plurinational State of)' else
                                    'Iran' if x == 'Iran (Islamic Republic of)' else
                                    'Micronesia' if x == 'Micronesia (Federated States of)' else
                                    'South Korea' if x == 'Republic of Korea' else
                                    'North Macedonia' if x == 'The former Yugoslav republic of Macedonia' else
                                    'Philippines' if x == 'Timor-Leste' else
                                    'Venezuela' if x == 'Venezuela (Bolivarian Republic of)' else x)

df['Country'] = df['Country'].map(lambda x:country_to_continent(x))

df['Country'].value_counts()

import matplotlib.pyplot as plt

for year, group in df.groupby("Year"):
    counts = group.groupby(["Country", "Status"]).size().unstack(fill_value=0)
    counts.plot(kind="bar", stacked=False, figsize=(8,5))
    plt.ylabel("Number of Countries")
    plt.title(f"Developing vs Non-developing by Continent ({year})")
    plt.xticks(rotation=45)
    plt.legend(title="Developing")
    plt.show()

import matplotlib.pyplot as plt

# Group by Year + Continent and compute average life expectancy
lifeexp_time = df.groupby(["Year", "Country"])["Life expectancy "].mean().reset_index()

# Pivot so each continent is a separate line
pivot = lifeexp_time.pivot(index="Year", columns="Country", values="Life expectancy ")

# Plot
pivot.plot(figsize=(10,6), marker="o")
plt.ylabel("Average Life Expectancy")
plt.xlabel("Year")
plt.title("Average Life Expectancy vs Year by Continent")
plt.legend(title="Continent")
plt.show()

import matplotlib.pyplot as plt

# Group by Year + Continent and take the average GDP per continent per year
gdp_time = df.groupby(["Year", "Country"])["GDP"].mean().reset_index()

# Pivot so that each continent is a separate column
pivot = gdp_time.pivot(index="Year", columns="Country", values="GDP")

# Plot
pivot.plot(figsize=(10,6), marker="o")
plt.ylabel("Average GDP")
plt.title("GDP vs Time by Continent")
plt.legend(title="Continent")
plt.show()

# Group by Year + Continent and sum the population
pop_time = df.groupby(["Year", "Country"])["Population"].sum().reset_index()

# Pivot so each continent is a separate line
pivot = pop_time.pivot(index="Year", columns="Country", values="Population")

# Plot
pivot.plot(figsize=(10,6), marker="o")
plt.ylabel("Total Population")
plt.xlabel("Year")
plt.title("Total Population vs Year by Continent")
plt.legend(title="Continent")
plt.show()

import matplotlib.pyplot as plt

# Group by Year + Continent and compute average infant deaths
infant_time = df.groupby(["Year", "Country"])['infant deaths'].mean().reset_index()

# Pivot so each continent is a separate line
pivot = infant_time.pivot(index="Year", columns="Country", values='infant deaths')

# Plot
pivot.plot(figsize=(10,6), marker="o")
plt.ylabel("Average Infant Deaths")
plt.xlabel("Year")
plt.title("Average Infant Deaths vs Year by Continent")
plt.legend(title="Continent")
plt.show()

import matplotlib.pyplot as plt

# Group by Year + Continent and compute average infant deaths
infant_time = df.groupby(["Year", "Country"])['Alcohol'].mean().reset_index()

# Pivot so each continent is a separate line
pivot = infant_time.pivot(index="Year", columns="Country", values='Alcohol')

# Plot
pivot.plot(figsize=(10,6), marker="o")
plt.ylabel("Average Infant Deaths")
plt.xlabel("Year")
plt.title("Average Adult Alcohol Consumption vs Year by Continent")
plt.legend(title="Continent")
plt.show()

import matplotlib.pyplot as plt

# Group by Year + Continent and compute average infant deaths
infant_time = df.groupby(["Year", "Country"])['Adult Mortality'].mean().reset_index()

# Pivot so each continent is a separate line
pivot = infant_time.pivot(index="Year", columns="Country", values='Adult Mortality')

# Plot
pivot.plot(figsize=(10,6), marker="o")
plt.ylabel("Average Infant Deaths")
plt.xlabel("Year")
plt.title("Average Adult Alcohol Consumption vs Year by Continent")
plt.legend(title="Continent")
plt.show()

import matplotlib.pyplot as plt

# Group by Year + Continent and calculate averages
agg = df.groupby(["Year", "Country"]).agg({
    "Life expectancy ": "mean",
    "Alcohol": "mean"
}).reset_index()

# Plot per continent
for continent, group in agg.groupby("Country"):
    fig, ax1 = plt.subplots(figsize=(8,5))

    # Life expectancy (left y-axis)
    ax1.plot(group["Year"], group["Life expectancy "], color="tab:blue", marker="o", label="Life Expectancy")
    ax1.set_xlabel("Year")
    ax1.set_ylabel("Average Life Expectancy", color="tab:blue")
    ax1.tick_params(axis="y", labelcolor="tab:blue")

    # Alcohol (right y-axis)
    ax2 = ax1.twinx()
    ax2.plot(group["Year"], group["Alcohol"], color="tab:red", marker="s", linestyle="--", label="Alcohol Consumption")
    ax2.set_ylabel("Average Alcohol Consumption", color="tab:red")
    ax2.tick_params(axis="y", labelcolor="tab:red")

    # Title
    plt.title(f"Evolution of Life Expectancy & Alcohol Consumption in {continent}")
    fig.tight_layout()
    plt.show()

df = df.dropna(subset=["Life expectancy "])

df.isnull().sum()

corr = df.drop(columns = ['Country','Status']).corr()
corr['Life expectancy '].sort_values(ascending = False)

df.drop(columns = ['Country','Status']).var().sort_values(ascending= False)

from sklearn.model_selection import train_test_split

x_train,x_test,y_train, y_test = train_test_split(df.drop(columns = ['Life expectancy ']), df['Life expectancy '], test_size = 0.2, random_state = 23)

from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OrdinalEncoder,OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.base import TransformerMixin

class Delete(TransformerMixin):

  def fit(self,X , y= None):
    return self

  def transform(self,X):
    col = 18
    X_new = np.delete(X,  col, axis=1)
    return X_new

num_pipeline = Pipeline([
 ('imputer', SimpleImputer(strategy="median")),
 ('del_attrib', Delete()),
 ('std_scaler', StandardScaler()),
 ])


num_att = x_train.drop(columns = ['Country','Status']).columns.to_list()
cat_att = ['Country','Status']
full_pipeline = ColumnTransformer([
    ('num',num_pipeline,num_att),
    ('cat',OneHotEncoder(),cat_att),
])

x_train_transformed = full_pipeline.fit_transform(x_train)

x_train_transformed.shape

from sklearn.linear_model import LinearRegression
lin_reg = LinearRegression()
lin_reg.fit(x_train_transformed,y_train)
predicted_linear_train = lin_reg.predict(x_train_transformed)

from sklearn.tree import DecisionTreeRegressor
tree = DecisionTreeRegressor()
tree.fit(x_train_transformed,y_train)

predicted_tree_train = tree.predict(x_train_transformed)

from sklearn.ensemble import RandomForestRegressor
forest = RandomForestRegressor()
forest.fit(x_train_transformed,y_train)

predicted_forest_train = forest.predict(x_train_transformed)

from sklearn.metrics import mean_squared_error
import numpy as np
MSE_train_linear = mean_squared_error(y_train,predicted_linear_train)
MSE_train_tree = mean_squared_error(y_train,predicted_tree_train)
MSE_train_forest = mean_squared_error(y_train,predicted_forest_train)
print(f'RMSE_train_linear: {np.sqrt(MSE_train_linear)}\nRMSE_train_tree: {np.sqrt(MSE_train_tree)}\nRMSE_train_forest: {np.sqrt(MSE_train_forest)}')

from sklearn.model_selection import cross_val_score
scores_linear = cross_val_score(lin_reg,x_train_transformed,y_train,cv = 10, scoring = 'neg_mean_squared_error')
scores_linear = np.sqrt(-scores_linear)

scores_tree = cross_val_score(tree,x_train_transformed,y_train,cv = 10, scoring = 'neg_mean_squared_error')
scores_tree = np.sqrt(-scores_tree)

scores_forest = cross_val_score(forest,x_train_transformed,y_train,cv = 10, scoring = 'neg_mean_squared_error')
scores_forest = np.sqrt(-scores_forest)

print(f"Mean_Score_CV_linear: {scores_linear.mean():.2f}")
print(f"Std_CV_linear: {scores_linear.std():.2f}")

print(f"Mean_Score_CV_tree: {scores_tree.mean():.2f}")
print(f"Std_CV_tree: {scores_tree.std():.2f}")

print(f"Mean_Score_CV_forest: {scores_forest.mean():.2f}")
print(f"Std_CV_forest: {scores_forest.std():.2f}")

test_score = [round(np.sqrt(MSE_train_linear),2),
              round(np.sqrt(MSE_train_tree),2),
              round(np.sqrt(MSE_train_forest),2)]

CV_score = [round(scores_linear.mean(),2),
            round(scores_tree.mean(),2),
            round(scores_forest.mean(),2)]

score_diff = [round(y - x,2) for x,y in zip(test_score,CV_score)]

std = [round(scores_linear.std(),2),
       round(scores_tree.std(),2),
       round(scores_forest.std(),2)]

models = ['Linear Regression','Decision Trees','Random Forest']

comparisons = {
    'Models': models,
    'Training Set': test_score,
    'K-Fold': CV_score,
    'Difference': score_diff,
    'CV Standard Deviation': std
}

comparison_df = pd.DataFrame(comparisons).set_index("Models")

comparison_df


#Among the three models evaluated, the Random Forest algorithm demonstrated the best overall performance.
#It achieved the lowest cross-validated RMSE at 1.91 with a standard deviation of 0.23, indicating that its
#predictions are both accurate and stable across folds. By comparison, Linear Regression produced a
#cross-validatedRMSE of 3.87 with a standard deviation of 0.26. While its train and validation scores were close
#(RMSE difference of only 0.05), suggesting minimal overfitting, its overall error was higher than that of the Random Forest.
#On the other hand, Decision Trees showed clear signs of overfitting: the training RMSE was nearly 0.00, #
#but the cross-validated RMSE increased sharply to 2.75, with a standard deviation of 0.24. This large gap between training
#and validation performance confirms poor generalization. In conclusion, the Random Forest strikes the best balance between
#bias and variance, outperforming both Linear Regression and Decision Trees in terms of predictive accuracy and stability.

from sklearn.model_selection import GridSearchCV

# Define a smaller parameter grid (because Grid Search tests *all* combinations)
params = [
 {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8,12,14,16,18,20,22]},
 {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},
 ]


grid_search = GridSearchCV(
    estimator=forest,
    param_grid=params,
    cv=10,
    scoring='neg_mean_squared_error',
    n_jobs=-1)

grid_search.fit(x_train_transformed, y_train)

print("Best parameters (Grid Search):", grid_search.best_params_)
print("Best CV score (RMSE):", np.sqrt(-grid_search.best_score_))

final_model_forest = grid_search.best_estimator_
x_test_prepared = full_pipeline.transform(x_test)
final_predictions = final_model_forest.predict(x_test_prepared)
final_mse = mean_squared_error(y_test, final_predictions)
final_rmse = np.sqrt(final_mse)
print(f'Final RMSE: {final_rmse:.2f}')

from sklearn.metrics import r2_score

r2_test = r2_score(y_test, final_predictions)
print(f"RÂ² test:  {r2_test:.3f}")

import matplotlib.pyplot as plt

# Assuming y_test and final_predictions are provided
# Create x-axis as sample indices
x_axis = range(len(y_train))

# Scatter plot for actual data
plt.scatter(x_axis, y_train, color='blue', label='Actual', alpha=0.5)

# Line plot for predicted values
plt.plot(x_axis, predicted_forest_train, color='orange', label='Predicted', linewidth=2)

# Add prominent grid
plt.grid(True, linestyle='-', linewidth=1, alpha=0.7)

# Labels and title
plt.xlabel('Sample Index')
plt.ylabel('Life Expectancy')
plt.title('Actual vs Predicted Life Expectancy')

# Add legend
plt.legend()

# Show plot
plt.show()

import matplotlib.pyplot as plt

# Assuming y_test and final_predictions are provided
# Create x-axis as sample indices
x_axis = range(len(y_test))

# Scatter plot for actual data
plt.scatter(x_axis, y_test, color='blue', label='Actual', alpha=0.5)

# Line plot for predicted values
plt.plot(x_axis, final_predictions, color='orange', label='Predicted', linewidth=2)

# Add prominent grid
plt.grid(True, linestyle='-', linewidth=1, alpha=0.7)

# Labels and title
plt.xlabel('Sample Index')
plt.ylabel('Life Expectancy')
plt.title('Actual vs Predicted Life Expectancy')

# Add legend
plt.legend()

# Show plot
plt.show()

df.columns

